Predatory Conduct: More Recent Developments 339


13.5 PREDATION AND ANTITRUST POLICY


In the wake of the Great Depression—a period of falling prices and many small firm
bankruptcies—and with the history of the aggressive tactics of firms such as Standard Oil
and NCR still fresh, it was perhaps natural that a wide consensus formed that predatory
pricing was widespread and harmful. The most visible manifestation of that view was
the passage of the Robinson-Patman Act of 1936 which, among other things, prevented
selective price discounts by large firms that would disadvantage smaller firms. Over time
however, this legislation was seen as less protective of competitive markets and more
protective of specific competitors against more efficient rivals. Subsequently, against a
history of cases such as _Utah Pie_, the work of McGee (1958, 1980), Koller (1971), Posner
(1976), Bork (1978), Easterbrook (1984), and others of the Chicago School reflected a
necessary corrective. Many firms achieve dominance not because of predation but because
of their superior competitive skill. Hence, policies that constrain “bigness” would have
adverse incentive effects on competitive behavior. A corollary to this view is that market
dominance will not persist if it is due to any factor not related to superior skill or efficiency.
Indeed, these very arguments were later made by Microsoft during its 1998–2001 trial and
appeal. As a result of the force of these arguments, the Chicago School perspective on
predatory behavior became increasingly influential. It received an official blessing in the
1986 _Matsuhita_ case when the Supreme Court wrote, “For this reason, there is a consensus
among commentators that predatory pricing schemes are rarely tried, and even more rarely
successful.” [16] A few years later in the _Brooke_ case of 1993, the Court went even further
and outlined stringent evidentiary standards that had to be met before a predation claim
would be supported. [17]

The Brooke Group (also known as Ligget) was a small cigarette manufacturer that began
selling a generic brand in 1980, at prices well below those of the major brands. When
consumers responded favorably to the introduction of these cheap cigarettes, Brown &
Williamson and other large tobacco companies responded with vigorous price cuts. In its
effort to undersell Brooke, it seems clear that Brown cut prices so low that it sustained
millions of dollars of losses over a period as long as a year or more. Ultimately, however,
Brooke could not keep pace. It raised the price on its cigarettes. Almost immediately
thereafter, Brown & Williamson and other cigarette manufacturers did the same.

The Supreme Court did not find the foregoing evidence conclusive. In the wake of
the Chicago School revival, the Court had moved to a view that there was an economics
consensus that predatory pricing was irrational. The Court did, however, take the opportunity
to establish two broad requirements for the successful prosecution of a predatory pricing
case. The first was evidence of selling below some measure of cost. The second and
really new element introduced by the court was evidence that the predator had a reasonable
expectation of recouping the losses endured during the predatory period. Just how strong the
new requirements were can be seen in the fact that there was not one successful prosecution
of predatory action in the first forty cases that followed the Brooke decision. It was not until
the important case of Microsoft that there was a finding of criminal guilt.

In our view, the consensus to which the Supreme Court referred in _Matsuhita_ no longer
exists—if it ever did. Commitment via capacity expansion, asymmetric information, and


16 _Brooke Group v. Brown & Williamson Tobacco_ 509 U.S. 209 (1993). Interestingly enough, Brooke
actually won the initial jury trial but lost in subsequent appeals to the federal courts.
17 See Scherer’s (1976) exchange with Areeda and Turner (1976) on this and other points.


340 Anticompetitive Behavior and Antitrust Policy


contractual exclusions are all features that can be combined to make a coherent argument
for the rationality of predatory actions. Here, the reputation effects of successful predation
in one market are particularly important. In measuring the ability of a firm to recover its
losses, one has to include in the calculations all the profits secured by the deterrent effect
that the firm’s reputation has on other would-be entrants in other markets and time periods.

However, the Court’s statement of necessary evidence does speak to an important issue.
The recognition that predation can be rational and can happen does not carry any clear policy
implications unless we have a clear standard by which predatory actions can be identified
and distinguished from conduct that is truly procompetitive. Any entry will generally evoke
some reaction from the incumbent firms. Typically, this may come in the form of lower
prices or other expanded consumer benefits. Most such responses are not predatory in
nature. To the contrary, they are exactly the conduct that we expect and hope that markets
will promote. Similarly, when any firm, large or small, first comes into a market as a new
entrant, it may want to set a low initial price, lower than the short-term, profit-maximizing
one, as a way to induce consumers to forego their usual brand and try the entrant’s relatively
unknown product. Once established, the firm may then raise price. Clearly, the intent of this
kind of promotional pricing is not to drive a rival from the market. Yet it may be difficult
empirically to distinguish this pricing strategy from predatory pricing.

In other words, to the extent that antitrust enforcement seeks to prevent predatory
practices, policy makers need to create workable legal standards that are able to distinguish
procompetitive from anticompetitive conduct. Ideally, we would like such policy to be
governed by a simple rule that could be used to detect the presence of predation. This
would permit all parties to understand just what is and what is not legal. Yet in the area of
predation simple rules rarely work.

Of the various rules that have been proposed, the most famous is that of Areeda and
Turner (1975), which essentially finds any price to be predatory if it is below the firm’s
short-run average variable cost standing in as a proxy for marginal cost. Unfortunately, it
is not a very good proxy. In actual practice, average variable cost can be significantly less
than short-run marginal cost so that a firm could set a price below its current marginal cost
yet still above its average cost. In so doing, the firm would be acting within the legal range
permitted by the Areeda and Turner rule even though a price below short-run marginal cost
would likely be judged as predatory by many economists. Hence, as Scherer (1976) was
quick to point out, the use of the average cost standard could still permit serious predation. [18]

Moreover, if there are important learning curve effects so that average cost falls with a
firm’s cumulative production over time (as opposed to scale economies in which average
cost falls with the volume of production per unit of time), predation can occur by means of
a vigorous output expansion without prices ever falling below cost. [19]

Another problem is that the rule ignores the strategic aspect of predatory pricing. To take
a simple example, consider a market in which there is one firm operating as a monopoly.
Suppose that if a new firm enters it will produce an identical good to that of the monopolist
and that the game is one of Bertrand or price competition. As we saw in Chapter 10, the
equilibrium of this game is that prices fall immediately to their marginal cost. By Areeda
and Turner’s rule, this would not be predatory. Yet if the entrant foresees this outcome,
the existence of any sunk entry cost will be enough to induce it to stay out. Here again,


18 See Cabral and Riordan (1997) for an elaboration of this point.
19 See, for example, his decision in _Barry Wright Corporation v. ITT Grinnell Corporation, et al_ ., 724F. 2d
227 (1st Cir. 1983).


Predatory Conduct: More Recent Developments 341


the Areeda and Turner rule might permit entry-deterring behavior. Whenever the threat of
“cutthroat pricing” is sufficiently credible that it never is actually used, the evidence Areeda
and Turner look for will not be found.

Despite its shortcomings, the Areeda and Turner rule has been applied in many US
antitrust cases. It has been frequently relied upon by Supreme Court Justice, Stephen
Breyer. It was also used to exonerate IBM against predatory price-cutting charges in
_California Computer Products, Inc., et al. v. International Business Machines_ [613 F. 2d
727 (9th Cir. 1979)]. Perhaps the clearest statement is that of Judge Kaufman who, in
_Northeastern Telephone Company v. American Telephone and Telegraph Company et al._,

[651 F. 2d 76 (2nd Cir. 1981)], wrote: “We agree with Areeda and Turner that in the general
case, at least, the relationship between a firm’s prices and its marginal costs provides the
best single determinant of predatory pricing.”

Nevertheless, the weaknesses in the Areeda and Turner rule have led many economists
to propose modified alternatives. Some of these are like the Areeda and Turner approach in
that they focus essentially on the behavior of a single variable. Baumol (1979), for example,
focuses primarily on the behavior of the incumbent’s price before entry and after exit of
a rival. Essentially, this rule requires that any price reduction by a dominant firm in the
face of entry be required to be “quasi-permanent,” say for a period of five years. If the
price reduction that entry induced is quickly reversed following the entrant’s exit, Baumol’s
(1979) rule would find the pricing behavior predatory.

In a later updating of this work, Baumol (1996) also suggests comparing the predator’s
price with a measure of Average Avoidable Cost (AAC). AAC is a measure of the cost
that the alleged predator could have avoided had it not engaged in the predatory increase in
output. Thus, if the predatory action lasted for a year, AAC would be the total amount of
extra costs incurred in that year divided by the extra quantity produced. In a similar vein,
Williamson (1977) suggests looking at the incumbent’s _output_ before and after entry. The
idea is that a rapid expansion of output after entry would be a sign of possible predation. This
rule has two advantages. First, because of the suspicion raised by expansion after entry, the
incumbent might well expand output earlier. In turn, this eliminates some of the monopoly
distortion that would otherwise occur when the incumbent is alone in the market. Second,
Williamson’s rule may also prevent capacity expansion as an entry-deterring strategy by
making the threat to expand once entry is no longer credible.

While both the Baumol (1979) and Williamson (1977) rules are insightful, both are also
limited by focusing on a single variable to indicate predation. As we have emphasized,
predatory conduct is part of an often complicated corporate strategy. As a result, it is
unlikely to be reflected accurately in the behavior of a single variable. The Dixit (1980)
model of capacity deterrence does not involve pricing at all and so would go undetected
by both the Areeda-Turner and the Baumol tests. Similarly, Williamson’s test would not
prevent deterrence by preemption. None of these tests involve any consideration as to
whether the strategic environment actually permits predation.

Joskow and Klevorick (1979) were among the first to suggest a more complete assessment
of alleged predation within a strategic framework. Their rule combines the separate criteria
mentioned above—below-cost pricing, output expansion, and price reversal—but requires
as well that there be evidence that such actions were or at least could have been conceived as
part of an overall strategy. In particular, Joskow and Klevorick (1979) propose to examine
company documents to determine whether or not a firm was intentionally pursuing the
aggressive policies. These authors would also examine the industry’s structural features to
see whether the conditions for predatory pricing exist.


342 Anticompetitive Behavior and Antitrust Policy


Ordover and Willig (1981) and Bolton, Brodley, and Riordan (2001) also try to present
a comprehensive framework for evaluating predatory accusations. The Ordover and Willig
(1981) paper is important for its clear and modern definition of predatory conduct as any
action for which the profitability is dependent on driving the rival out or preventing it from
entering in the first place. In this view, predatory pricing is but one of a number of predation
tactics. Both papers argue that an important first step is to check the market structure for
the preconditions necessary to make predation worthwhile. The structural conditions so
identified are that the accused predator really has significant market power and that entry be
difficult so that if a rival is forced to exit, it is not subsequently replaced. Brodley, Bolton, and
Riordan (2001) also argue that recoupment can be demonstrated by relating the predator’s
actions to a clear and evidence-supported strategy of predation. In the case of predatory
pricing, these authors would rely on an Average Avoidable Cost measure as a benchmark.

None of the proposed predatory standards is simple or easily translated into a courtroom
proceeding. The difficulty of distinguishing between good, fierce competition, on the one
hand, and predatory efforts, on the other, is substantial. Moreover, as tough as this distinction
is to make in the case of pricing, it may be even more difficult to achieve in considering
other actions.

For example, consider the alleged predatory product innovations key to two well-known
cases, _Telex v. IBM_, and _Berkey v. Kodak_ . In the former, the issue at hand was the claim
by Telex (and others) that IBM, which at the time admittedly controlled the market for
mainframe computers but faced serious competition in markets for peripheral equipment,
began to develop new equipment designs so that only new IBM peripherals were compatible
with IBM mainframes (a tying arrangement). In the _Berkey_ case, Berkey was a photo-finisher
and camera manufacturer that claimed that Kodak should have given it advance notice
of Kodak’s introduction of a new 110 camera film so as to permit Berkey to redesign its
cameras and remain viable in the market. In both cases, the courts eventually ruled against
the plaintiffs and in favor of IBM and Kodak, respectively. There is perhaps good reason to
believe that the technological alterations reflected in these two cases truly were motivated
by predatory considerations. However, there is also a legitimate fear that punishing such
actions could have a chilling effect on all innovation.


13.6 EMPIRICAL APPLICATION: ENTRY DETERRENCE IN THE
PHARMACEUTICAL INDUSTRY


We noted that legal cases concerning predatory and entry deterring behavior often founder
for lack of a clear standard defining predation. It is equally difficult to find clear evidence of
such efforts in formal econometric studies. To be sure, the case histories such as Weiman and
Levin (1994) concerning AT&T and the Brevoort and Marvel (2004) paper studying NCR
offer clear specific examples. In a widely-cited paper on shipping cartels, Scott-Morton
(1997) does find some formal evidence that established cartels in the late 19th and early
20th century engaged in predatory pricing to deter new shipping entrants, especially when
the entrants were small and/or had poor financial resources. However, in another paper,
Scott-Morton (2000) Morton finds very little statistical evidence that pharmaceutical firms
successfully use advertising to deter generic entry as the end of the incumbent’s patent
nears.

The unfortunate truth is that the formal econometric requirements necessary to identify
consistently any systematic predatory behavior across a set of market data points are fairly


Predatory Conduct: More Recent Developments 343



![](/Users/nicholasvreugdenhil/ASU Dropbox/Nicholas Vreugdenhil/masters_io_2026/external/peppall_textbook_chunks/markdown/peppall_textbook_chunk15_p351-375_images/peppall_textbook_chunk15_p351-375.pdf-4-2.png)







demanding. One reason for this is that such work must somehow identify cases where an
incumbent both regarded entry as a real threat _and_ felt that there was a way to prevent
it. Suppose, for instance, that the data set includes two kinds of markets. One type is
characterized by a high likelihood of entry by several new firms and that by taking a
costly action X the incumbent can reduce the number of entrants. The other market type
is characterized by a very low probability of entry and by one new rival at most. Finally,


344 Anticompetitive Behavior and Antitrust Policy


suppose that post-entry competition is Cournot so that the fewer new entrants the better
from the viewpoint of the incumbent.

In such a setting, we may find that incumbents only take action X in the first type of
market because entry is so unlikely in the second kind of market that incurring the cost of
action X is not worthwhile. If this is so, the data will be divided into two groups. In one set
of cases, the incumbent takes action X and there is some entry (though less than otherwise
would have been the case). In the other set of cases, the incumbent does not take action X,
yet there is no entry. Thus, on balance, the data will show that there is _more_ entry when the
predatory tactic X is used than when it is not. Unless care is taken to identify such markets
_a priori_, it will be hard to conclude from such data that predation is a serious threat.

Another difficulty that the researcher must overcome is identifying the entry-deterring
strategy. This too is trickier than it may at first appear. Consider the first-mover, consumer
learning-by-doing model of Gabszewicz, Pepall, and Thisse (1992) discussed in Chapter 11.
Recall that in the first period of that model when the incumbent is alone, the incumbent
prices low to “buy up” a cohort of customers who will be loyal to its product after the
second-period entry of a rival because these customers have learned how to work with the
incumbent’s brand. On the one hand, then, such aggressive pricing may seem as if it deters
entry because it limits the number of customers for whom the later entrant can compete.
On the other hand, however, the fact that it has such a loyal and price-insensitive cohort
encourages the incumbent to charge a high price when entry occurs, and this allows the
entrant to gain more consumers at a high price as well. Of course, this latter effect makes
entry more likely.

A recent paper that nicely illustrates these issues is Ellison and Ellison (2011). They
look at the advertising and pricing behavior of pharmaceutical companies in the case of
sixty-four drugs about to lose their patents over the years 1986–92. They first do a simple
regression to determine which markets are most vulnerable to entry. For this purpose, they
code each market as to whether or not there was any generic entry within three years after
the expiration of the incumbent’s patent. This procedure creates a 1, 0 variable for each
market called Entry, where the variable is 1 if there was entry and 0 if there was not. Ellison
and Ellison (2011) then try to explain this entry variable with an equation that includes
three right-hand-side variables that should be related to entry. These are: Rev _i,_ the average
annual revenue earned by the incumbent over the three years prior to patent expiration;
Hosp _i,_ the fraction of revenues from the drug due to hospital sales in the year prior to
patent expiration; and Chronic/Acute _i,_ which takes on the value 0 if the drug treats an acute
condition but 1 if it treats a chronic condition. Their estimated equation then is:


Entry _i_ constant _β_ 1Rev _i_ _β_ 2Hosp _i_ _β_ 3Chronic _/_ Acute _i_ _εi_ (13.3)
= + + + +

where _εi_ represents random factors that may affect entry in the _i_ th market.

Because the dependent variable is not continuous but instead either 1 or 0, equation
(13.3) cannot be efficiently estimated by ordinary least squares (OLS) regression. The linear
feature of OLS means that it is quite likely that for plausible values of the independent
variables the OLS estimates of the _βk_ coefficients will predict a value for entry outside the

[0,1] interval.

Instead, Ellison and Ellison (2011) use an alternative regression procedure called Probit.
This procedure effectively transforms the data so that for any value of the right-hand-side
variables, the coefficient estimates give rise to a value for Entry _i_ that lies between 0 and 1.
This predicted value is then a measure of the probability of entry given the market features.


Predatory Conduct: More Recent Developments 345


In turn, this allows them to classify each of their sixty-four markets as one of three types: 1)
low probability of entry; 2) intermediate probability of entry; and 3) high probability of
entry.

Ellison and Ellison (2011) next consider the strategic use of advertising to deter entry
in these markets. They start by noting that in these cases advertising by one firm has
considerable spillover to the products of another. In particular, advertising by an incumbent
calls attention to the specific functions of the drug, its potential benefits, its proper use, and
so on, in a way that is likely to inform consumers of the benefit of later generic rivals. This
is particularly the case with drugs because doctors are smart enough to realize that the active
ingredients in branded medications and generics are chemically identical. It is even more
the case in those states in which pharmacies are required by law to fill a prescription with a
cheaper generic medication if one is available and the doctor has not explicitly forbidden it.
In other words, Ellison and Ellison (2011) assume that advertising by an incumbent today
will _help_ tomorrow’s generic entrant. Hence, if incumbents wish to deter entry, they should
_reduce_ advertising in the period prior to the expected emergence of a rival. Note how this
implies a further complication in evaluating the evidence on entry deterrence. The other
strategies we considered, e.g., capacity expansion and price-cutting, are actions that are
expensive for the firm. By reducing advertising, however, the firm also lowers its expense.

Of course, whether or not incumbents will wish to deter entry will depend in part on
how likely entry is. A key insight of the Ellison and Ellison (2011) paper is that the
relationship between the probability of entry and strategic deterrence efforts is likely to
be nonmonotonic. This is because entry deterrence is probably not worth the cost either
in markets where entry is highly probable or in ones where it is very unlikely. In the first
case, no amount of deterrence is likely to prevent entry. In the second case, no deterrence
is really necessary. Thus, Ellison and Ellison (2011) predict that deterrence efforts will first
rise (relative to what they would otherwise be) as the probability of entry rises from a low
value to an intermediate one, and then fall, as the probability of entry rises still further to a
high value. In terms of advertising, this means that incumbents will _lower_ their advertising
in those markets that their Probit regression results characterize as having an intermediate
probability of entry but exhibit no advertising response to the threat of entry in either low or
high probability of entry markets. Again, this is because Ellison and Ellison (2011) assume
that advertising by the incumbent also has strong benefits for the generic entrant. Reducing
advertising prior to the period of potential entry can then make that entry less likely. To
some extent, this is precisely what they find.

Consider so-called detail advertising. By this we mean the promotional efforts of
pharmaceuticals to influence physicians’ prescribing practices by visiting doctors and
health care providers and making direct presentations in their offices. Ellison and Ellison
(2011) look at the time trend in the value of detail advertising relative to its average in
the three years prior to patent expiration for each month starting 36 months before that
expiration and continuing for 12 months after by estimating the regression equation:



_Advertisingit_
_Average Advertisingi_



1 _(β_ 1 _LowEntryi_ _β_ 2 _IntermedEntryi_ _β_ 3 _HighEntryi)Time_ _εit_

- = + + +

(13.4)


346 Anticompetitive Behavior and Antitrust Policy


**Table 13.1** Detail advertising trend by category of entry
probability, 64 pharmaceutical markets


_Coefficient_ _Estimated Value_ _Standard Error_


_β_ 1 0.007 0.013

           _β_ 2 0.032 0.009

           _β_ 3 0.009 0.007


The _Time_ variable is just a trend term that increases by one as one moves a month closer to
expiration date. The dependent variable is the ratio of advertising in the _i_ th market in month
_t_ relative to average monthly detail advertising in that market. LowEntry, IntermedEntry,
and HighEntry are each a 1,0 dummy variable indicating what entry category market _i_ is
in. The hypothesis is that _β_ 2 will be significantly less than either _β_ 1 or _β_ 2 _,_ reflecting the
efforts of incumbents in these markets to reduce advertising as a means of deterring entry.
The estimated results are shown in Table 13.1 above.

As you can see, the estimate of _β_ 2 is noticeably smaller (algebraically) than either of the
other two coefficients. That is, the results imply that while the incumbent’s detail advertising
declines by less than 1 percent per month relative to the norm in high entry markets _(β_ 1 _)_
and actually rises a bit in low entry markets _(β_ 3 _),_ it falls by over 3 percent per month in
markets with an intermediate chance of entry. Thus, Ellison and Ellison (2011) provide
some interesting evidence of strategic deterrence efforts in US pharmaceutical markets in
the late 1980s.


**Summary**



Allegations of pricing below cost to drive out
a competitor and other comparable predatory
strategies have been met in the last part of the
twentieth century with increasing skepticism by
the courts. This reflects the Chicago School view
that predation is irrational. In the language of
game theory, the Chicago view is that predation
is not a subgame perfect strategy and it is typically dominated by other choices. Accordingly,
few charges of predatory activity have been successfully prosecuted in the last twenty years or so.

At the same time, there appear to be clear
historical cases of actual predatory conduct. As
a result, an important question in contemporary
industrial organization theory has been whether
we can construct plausible models in which
predatory actions are rational. The answer turns
out to be yes and numerous game theoretic models have now been developed that overturn the
logic of the Chain Store Paradox.

An important common feature in many of these
models is asymmetric information. Asymmetries
between a lender and a firm regarding the firm’s



true profitability, or between an established firm
and an upstart regarding the incumbent’s cost can
make predation a feasible and attractive strategy.
Even without such uncertainty, long-term and/or
tying contracts can also be used to deny rivals
a market. Yet while the viability of predation in
both theory and practice seems clear, the proper
role of public policy remains clouded.

The principal problem is one of distinguishing aggressive pricing and other competitive strategies from ones that are truly
predatory—profitable only if they succeed in
driving a rival out of business. Some antitrust
enforcement—especially those cases prosecuted
under the Robinson-Patman Act in the first thirtyfive years after it was passed—appear to have
been misguided efforts to protect competitors and
not competition. Both economists and the courts
continue to struggle with the implementation
of a workable definition of predation. Empirical
work testing systematic entry deterrence has been
challenged by the data requirements necessary to
identify predatory behavior across a set of market


Predatory Conduct: More Recent Developments 347



data points. Nevertheless this is an active research
area in empirical industrial organization, holding


**Problems**


1. Return to the Microhard Newvel game as
discussed in section 13.1. Suppose now
that Newvel’s fixed costs are only $80 million per period. What would be the loan
contract that a bank in a competitive banking industry would accept to loan Newvel
$80 million in each period? Now suppose
that the worst case scenario facing Newvel
worsens. Specifically there is a 50 percent
chance of earning $200 million and a 50
percent chance of earning only $40 million.
Fixed costs are $80 million per period. Now
what would be the loan contract that a bank
in a competitive banking industry would
accept to loan Newvel $80 million in each
period?


2. Two firms are contending for a local market. The incumbent has a cost function of:
_C(qI_ _)_ 800 40 _qI_ . The upstart entrant
= +
has a cost function given by: _C(qE)_
=
1300 36 _qE_ . The industry inverse demand
+
function is given by: _P_ = 100 − _Q_, where
_Q_ is total industry output. Prior to the
upstart’s entry, the incumbent acted like a
profit-maximizing, uniform pricing monopolist. What price was it setting? What profit
net of fixed cost did it earn? Upon the
entry of the upstart rival, the incumbent
quickly dropped its price to $63. How do
you think the entrant will respond to this


**References**


Aghion, P., and P. Bolton. 1987. “Contracts as a

Barrier to Entry,” _American Economic Review_
77 (June): 388–401.
Areeda, P. E., and D. F. Turner. 1975. “Predatory

pricing and related practices under section 2
of the Sherman Act,” _Harvard Law Review_ 88
(February): 697–733.
Areeda, P. E., and D. F. Turner. 1976. “Scherer

on Predatory Pricing: A Reply,” _Harvard Law_
_Review_ 89 (March): 891–900.
Baumol, W. J. 1979. “Quasi-Permanence of Price

Reductions: A Policy for Prevention of Predatory Pricing,” _Yale Law Journal_ 89: 1–26.



promise for policy makers seeking to implement
and enforce antitrust laws on predatory behavior.


price? Does the incumbent’s price-cutting
constitute predation? Why or why not?

3. Suppose a buyer is willing to pay up to
$200 for one unit of some good. There
is currently only one supplier of the good
and its cost of supplying one unit of the
good is $100. Next period, a rival supplier
may appear in the market. The rival’s cost
of supplying the good is not known. It
is assumed to be uniformly distributed on
the interval [50,150]. Describe a long-term
contract that the current supplier can offer
the buyer that will be attractive to the buyer
and that at the same time will strengthen the
monopoly power of the current supplier.

4. An incumbent firm has a cost function

marginal cost is given by:given by: _CI_ = 100 + 1.5 _MCqI_ [2][. Hence, its] _I_ 3 _qI_ . A
recently entered rival has the cost function: =
_CE_ 100 75 _qE_ . Suppose the incumbent
sets a price of 74 and meets demand at that = +
price, where market (inverse) demand is
given by: _P_ = 100 − _Q_ .
a. Does the incumbent’s behavior violate
the Areeda-Turner rule of selling below
marginal cost?
b. Does the incumbent’s behavior violate
the Areeda-Turner rule when average
variable cost is used as a proxy for
marginal cost? Why or why not?


Baumol, W. J. 1996. “Predation and the Logic of

the Average Variable Cost Test,” _Journal of_
_Law & Economics_ 39 (April): 49–72.
Benoit, J. P. 1984. “Financially Constrained

Entry in a Game with Incomplete Information,” _Rand Journal of Economics_ 15 (Winter):
490–9.
Bolton, P., and D. Scharfstein. 1990. “A Theory

of Predation Based on Agency Problems in
Financial Contracting,” _American Economic_
_Review_, 80 (March): 93–106.
Bork, R. 1978. _The Antitrust Paradox_, New York:

Basic Books.


348 Anticompetitive Behavior and Antitrust Policy



Brandeis, L. 1913. “Cutthroat prices-the compe
tition that kills,” _Harper’s Weekly_ 15 (November): 10–12.
Brevoort, K., and H. Marvel. (2004). “Success
ful Monopolization through Predation: The
National Cash Register Company,” _Research_
_in Law and Economics_ 21 (January): 85–125.
Brodley, J., P. Bolton, and M. Riordan. 2001.

“Predatory Pricing: Strategic Theory and Legal
Policy,” _Georgetown Law Review_ 88 (August):
2239–330
Burns, M. R. 1986. “Predatory pricing and the

acquisition cost of competitors,” _Journal of_
_Political Economy_ 94 (April): 266–96.
Cabral, L. M. B., and M. J. Riordan. 1997.

“The Learning Curve, Predation, Antitrust, and
Welfare,” _Journal of Industrial Economics_ 45
(June):155–69.
Easterbrook, F. H. 1984. “The Limits of
Antitrust,” _The Texas Law Review_ 63 (January): 1–40.
Ellison, G., and S. Ellison. 2011. “Strategic Entry

Deterrence and the Behavior of Pharmaceutical Incumbents Prior to Patent Expiration,”
_American Economic Journal_ 3 (January):
1–36.
Dixit (1980)
Fudenberg, D., and J. Tirole. 1986. “A Signal
Jamming Theory of Predation,” _Rand Journal_
_of Economics_ 17 (Autumn): 366–76.
Gabszewicz, Pepall, and Thisse (1992)
Genesove, D., and W. Mullin. 1998. “Testing

Static Oligopoly Models: Conduct and Cost in
the Sugar Industry, 1890–1914,” _Rand Journal_
_of Economics_ 14 (Summer): 355–77.
Holmes (1996)
Joskow, P. L., and A. K. Klevorick. 1979. “A

Framework for Analyzing Predatory Pricing
Policy,” _Yale Law Journal_ 89 (December):
213–70.
Koller, R. H. II. 1971. “The Myth of Predatory

Pricing: An Empirical Study,” _Antitrust Law_
_& Economics Review_ 4 (Summer): 105–43.
Koller (1969)
McGee, J. S. 1958. “Predatory Price Cutting: the

Standard Oil (N.J.) case,” _Journal of Law and_
_Economics_ 1 (April):137 –169.
McGee, J. S. 1980. “Predatory pricing revisited,”

_Journal of Law and Economics_ 23 (October):
289–330.



Milgrom, P., and J. Roberts. 1982. “Limit Pric
ing and Entry under Incomplete Information:
An Equilibrium Analysis,” _Econometrica_ 50
(March): 443–60.
Ordover, J. A., and G. Saloner. 1989. “Preda
tion, Monopolization and Antitrust,” in _Hand-_
_book of Industrial Organization, Vol_ . 1, R.
Schmalensee and R. Willig, eds. Amsterdam:
North-Holland, 537–95.
Ordover, J. A., and R. Willig, 1981. “An Eco
nomic Definition of Predation: Pricing and
Product Innovation,” _Yale Law Journal_ 91
(1981): 8–53.
Posner, R. 1976. _Antitrust Law: An Economic_

_Perspective_, University of Chicago Press.
Philips, L. 1995. _Competition Policy: A Game_

_Theoretic Analysis_ . Cambridge: Cambridge
University Press.
Rasmusen, E. 2007. _Games and Information_, 4th

ed. Cambridge, MA: Basil Blackwell, Inc.
Rasmusen, E., J. M. Ramseyer, and J. Wiley.

1991. “Naked Exclusion,” _American Eco-_
_nomic Review_ 81 (December): 113745.
Saloner, G. 1987. “Predation, Mergers and

Incomplete Information,” _Rand Journal of_
_Economics_ 18 (Summer): 165–186.
Scherer, F. M. 1976. “Predatory Pricing and the

Sherman Act: A Comment,” _Harvard Law_
_Review_ 89 (March): 869–90.
Scott-Morton, F. 1997. “Entry and Predation:

British Shipping Cartels, 1879–1929,” _Jour-_
_nal of Economics and Management Strategy_ 6
(Winter): 679–724.
Scott-Morton, F. 2000. “Barriers to Entry, Brand

Advertising, and Generic Entry in the U.S.
Pharmaceutical Industry,” _International Jour-_
_nal of Industrial Organization_ 18 (October):
1085–124.
Weiman and Levin (1994)
Whinston, M. 1990. “Tying, Foreclosure, and

Exclusion,” _American Economic Review_ 80
(September): 837–59.
Williamson, O. E. 1977. “Predatory Pricing: A

Strategic and Welfare Analysis,” _Yale Law_
_Journal_ 87 (December): 284–340.
Yamey, B., S. 1972. “Predatory price cutting:

notes and comments,” _Journal of Law and_
_Economics_ 15 (April): 129–42.
Yergin, D., 1991. _The Prize_, New York: Simon

and Schuster.


# **14** **Price Fixing, Repeated Games, and Antitrust Policy**

On December 5, 2012, the European Commission announced the fines totalling 1.5 billion
($1.92 billion) on seven firms that had participated in two related, but distinct illegal
cartels. This is the largest single price-fixing fine ever imposed by the Commission and the
firms involved include some of world’s largest electronics firms such as LG Electronics,
Philips, Samsung, Panasonic, and Toshiba. [1] Notably, in this last case, the fine imposed on
Asahi/AGC was reduced by 50 percent to 113.5 million in return for that firm’s cooperation
with the cartel investigation and its providing information that helped expose the cartel.

The European case was related to an earlier case in the United States involving the liquid
crystal displays used in flat panel TVs and computer screens. That case also involved several
major electronics firms including Hitachi, Sharp, Samsung, and Toshiba. Settlements with
these firms in late 2011 and early 2012 resulted in fines totaling $1.1 billion. That was
before the final fine levied on Au Optronics of $500 million in September of 2012. That fine
matched the largest single fine the US authorities had ever levied on any price-fixing firm.

The good news is that the above conspiracies were caught and prosecuted. The bad news
is that such collusive agreements are not uncommon. Early in 2012, the United States levied
fines and prison sentences on three Japanese firms operating in the US that conspired to fix
the prices of key auto parts such as heater control panels. In November 2009, the European
Union Competition Directorate jointly fined Akzo, Ciba, Elf Aquitaine, and seven others

173 million ($260 million at the time) for fixing the price of plastic additives. In 2007,
European regulators fined five elevator manufacturers a total of 992 million (approximately
$1.4 billion) for operating a cartel that controlled prices in Germany, Belgium, Luxembourg,
and the Netherlands. The elevator case came just one month after another case involving
gas-insulated switch-gear products in which the Commission imposed fines totaling 750
million on eleven companies for their parts in a price-fixing cartel. A few years earlier,
the US Department of Justice imposed a total of more than $732 million on companies
operating a cartel to control the pricing of dynamic random access memory (DRAM).

Tables 14.1 and 14.2 show that these conspiracies are not isolated events. Since 1995,
the US Department of Justice has detected and successfully prosecuted thirty-eight cartels
in which the final fine was $50 million or more. If we extend the list to include fines


1 Details of the European Union cases can be obtained at http://ec.europa.eu/comm/competition/antitrust/
cases/index.html.


350 Anticompetitive Behavior and Antitrust Policy


**Table 14.1** US price-fixing violations yielding a corporate fine of $50 million or more since 1995


_Defendant(s) & Year_ _Product(s)_ _Fine (_ $Million _)_


Au Optronics Corporation (2012) Liquid Crystal Display Panels $500

F. Hoffmann-La Roche, Ltd. (1999) Vitamins $500

Yazaki Corporation (2012) Automobile Parts $470

LG Display (2009) Liquid Crystal Display Panels $400

Air France / KLM (2008) Air Transportation (Cargo) $350

Korean Air Lines Co., Ltd. (2007) Air Transportation (Cargo/Passenger) $300

British Airways (2007) Air Transportation (Cargo/Passenger) $300

Samsung Electronics & Semiconductor (2006) Dram $300

BASF AG (1999) Vitamins $225

Chi Mei Optoelectronics Corporation (2010) Liquid Crystal Display Panels $220

Furukawa Electric Co. Ltd. (2012) Automotive Wire Harnesses & Like Goods $200

Hynix Semiconductor Inc. (2005) Dram $185

Infineon Technologies Ag (2004) Dram $160

SGL Carbon Ag (1999) Graphite Electrodes $135

Mitsubishi Corp. (2001) Graphite Electrodes $134

Sharp Corporation (2009) Liquid Crystal Display Panels $120

Cargolux Airlines S.A. (2009) Air Transportation (Cargo) $119

Japan Airlines Co. Ltd (2008) Air Transportation (Cargo) $110

UCAR, Inc. (1998) Graphite Electrodes $110

Lan Cargo S.A./Aerolinhas Brasileiras S.A. (2009) Air Transportation (Cargo) $109

Archer Daniels Midland Co. (1996) Lysine & Citric Acid $100

Embraco North America (2011) Compressors $ 92

Elpida Memory, Inc. (2006) Dram $ 84

Dupont Dow Elastomers L.L.C. (2005) Chloroprene Rubber $ 84

Denso Corporation (2012) Automobile Parts $ 78

All Nippon Airways Co., Ltd. (2011) Air Transportation (Cargo & Passenger) $ 73

Takeda Chemical Industries, Ltd. (1999) Vitamins $ 72

Bayer Ag (2004) Rubber Chemicals $ 66

Chunghwa Picture Tubes, Ltd. (2009) Liquid Crystal Display Panels $ 65

Qantas Airways Limited (2008) Air Transportation (Cargo) $ 61

Cathay Pacific Airways Limited (2008) Air Transportation (Cargo) $ 60

Bilhar Establishment (2002) Construction $ 54

Daicel Chemical Industries, Ltd. (2000) Sorbates $ 53

Abb Middle East & Africa Participations Ag (2001) Construction $ 53

SAS Cargo Group, A/S (2008) Air Transportation (Cargo) $ 52

Crompton (2004) Rubber Chemicals $ 50

Haarmann & Reimer Corp. (1997) Citric Acid $ 50

Asiana Airlines Inc. (2009) Air Transportation (Cargo & Passenger) $ 50


Source: US Department of Justice, Antitrust Division, www.usdoj.gov/atr.


Price Fixing, Repeated Games, and Antitrust Policy 351


**Table 14.2** Cartel cases decided by the European
Commission since 1990 and associated fines in millions


_Period_ _Cases_ _Total Fines_


1990—94 10 344
1995—99 10 271
2000—04 30 3,157
2005—09 33 8,430
2010—12 16 5,358


of $10 million or more, the number grows to nearly 100. Table 14.2 shows that the European
case is similar. Since 1990 the European Commission has imposed fines in nearly 100 cases
running the total fines levied to close to 18 billion.

In short, cartels happen. There appears to be no shortage of firms that enter into collusive
agreements to fix prices and avoid competition. However, forming and maintaining a cartel
is not easy for two, closely related reasons. The first is that such agreements are _per se_
illegal. [2] That is, there is no justification that the courts will find acceptable. Both the
antitrust laws of the United States and the legal framework established in Europe’s Treaty
of Rome, as well as the laws of most other nations, are explicit in making any and all
collusion illegal and punishable by fines and (in the United States) possible imprisonment
of corporate officers. [3]

The second obstacle is that the automatic illegality of collusive agreements means that
the implicit contracts among the conspiring firms cannot be legally enforced. If one of the
cartel members decides to price below the cartel-agreed level or to produce more than its
cartel-authorized output quota, the other members cannot sue or take other legal action to
curtail the renegade firm. Hence, a cartel’s success requires that it find some extra-legal
means of enforcing its agreement.

In this chapter, we explore the formation of cartels. This includes determining the
techniques cartels may use to maintain their agreement and the conditions under which
such techniques are most likely to be successful. In addition, we also address how antitrust
authorities may best detect and prevent cartels.


14.1 THE PRISONER’S DILEMMA, REPEATED GAMES, AND THE
FOLK THEOREM


The central issue that a potential cartel must face is clear. There are extra profits to be
earned if each firm cooperates and holds production off the market to approximate more
closely the monopoly outcome. Unfortunately, the price/output choices necessary for this
are not typically part of a Nash equilibrium. [4]


2 Some regulatory agencies have power to grant antitrust immunity from _per se_ illegality.
3 If anything, the language of European Union law is even stronger in that it also treats “concerted practices”
based upon a “concordance of wills” as _per se_ illegal. In practice, however, the US and European policy is
nearly identical.
4 A terrific guide to the intuition underlying the cartel problem and, indeed, all of game theory is Schelling
(1960).


352 Anticompetitive Behavior and Antitrust Policy


Consider, for example the simple Bertrand model of price competition with identical
products. As we know, the Nash equilibrium for that case is for both firms to set price equal
to marginal cost. Obviously, they could both set the monopoly price and this would greatly
enhance the profit of each. The problem though is that with, say, firm 1 setting the monopoly
price, firm 2’s best response in _not_ to set that price but to undercut it. Alternatively, consider
the Cournot model. We know from Chapter 9 that if demand is given by _P_ = A − B _Q_ =
A B _(q_ 1 _q_ 2 _)_ and each firm has a constant marginal cost of _c_, the monopoly output is
_Q_ - _[M]_ = _(_ A + − _c)/_ 2B. Hence, to achieve the monopoly outcome each duopolist would need
to produce _q_ 1 _q_ 2 _(_ A _c)/_ 4B. Unfortunately for these firms, we also know that the
best response function for each is: = = - _q_ i _(_ A _c)/_ 2B- _q_ j _/_ 2 _(i, j_ 1,2 _i_ _j_ . Hence, if one
firm cooperates and produces one half of the total monopoly output, the best response of = - = ; ̸=
the rival is not to do the same but instead to produce three-fourths of the monopoly output,
thereby driving the price below the monopoly level. [5]

We illustrate the foregoing Bertrand and Cournot cases for the specific case of a market
in which demand is described by _P_ 150 _Q_ 150 _(q_ 1 _q_ 2 _)_ and in which each firm
has a constant marginal cost of _c_ = = $30. In each case, if the firms enter into a price-fixing − = - +
agreement, they will earn maximum industry profit by agreeing to cooperate to achieve
the monopoly price of $90. At that price, market demand is 60 units which we assume is
shared equally between the two firms so that each earns a profit of _πi_ _M_ $1,800. In the

=
Bertrand case, cheating on the agreement by either firm is very attractive as the assumption
of identical products means that only a trivial price cut is necessary for either firm to steal
the entire monopoly market from its rival and so double its profits to $3,600.

The temptation to defect from the agreement is weaker in the Cournot case but,
nevertheless, very real. Here, if, say, firm 1 produces its share of the monopoly output or 30
units, firm 2’s best response is to produce 45 units. With a total output of 75 units, the price
falls to $75. Hence, each firm now makes $75 − $30 = $45 on each unit with the result that
by cheating, firm 2 now earns $2,025, a 12.5 percent increase over its profits in the joint
monopoly outcome. Of course, defection by both firms is tantamount to the noncooperative


**Table 14.3(a)** Payoffs ($ thousands) to cooperation _(M)_ and defection _(D)_ in
the Bertrand duopoly game

|Col1|Col2|Strategy for Firm 2|Col4|
|---|---|---|---|
|||Cooperate_ (M)_|Defect_ (D)_|
|_Strategy for Firm 1_|Cooperate_ (M)_|_(_$1.8_,_ $1.8_)_|_(_$0_,_ $3.6_)_|
|_Strategy for Firm 1_|Defect_ (D)_|_(_$3.6_,_ $0_)_|_(_$_ε,_ $_ε)_|



**Table 14.3(b)** Payoffs ($ thousands) to cooperation _(M)_ and defection _(D)_ in the
Cournot duopoly game

|Col1|Col2|Strategy for Firm 2|Col4|
|---|---|---|---|
|||Cooperate_ (M)_|Defect_ (D)_|
|_Strategy for Firm 1_|Cooperate_ (M)_|_(_$1.8_,_ $1.8_)_|_(_$1.35_,_ $2.025_)_|
|_Strategy for Firm 1_|Defect_ (D)_|_(_$2.025_,_ $1.35_)_|_(_$1.6_,_ $1.6_)_|



5 Throughout this and succeeding chapters, we restrict our analysis to pure strategies. The reader should be
aware, however, that the analysis can be extended, with some qualifications, to include mixed strategies:
see, for example, Harsanyi (1973).


Price Fixing, Repeated Games, and Antitrust Policy 353



![](/Users/nicholasvreugdenhil/ASU Dropbox/Nicholas Vreugdenhil/masters_io_2026/external/peppall_textbook_chunks/markdown/peppall_textbook_chunk15_p351-375_images/peppall_textbook_chunk15_p351-375.pdf-14-2.png)







Nash equilibrium in both the Bertrand and the Cournot cases. Tables 14.3(a) and 14.3(b)
show the payoff matrices for these two games.

In short, cartel cooperation is not “natural” despite the large potential profit that it can
bring because cooperation is not a Nash equilibrium for either firm. Instead, each firm’s
best response is always to defect from the agreement even if the rival continues to keep to it.


354 Anticompetitive Behavior and Antitrust Policy


These situations are in fact examples of many games in which players share possibilities for
mutual gain that cannot be realized because of a conflict of interest. Such games are often
referred to as “prisoners’ dilemma” games because one of the earliest illustrations of this
case involved dealings between a prosecutor and two suspects. (See Practice Problem 14.1.)

The prisoners’ dilemma is clearly a real problem for any potential cartel. Unless there
is some way to overcome this conflict, it would appear that antitrust policy need not be
terribly worried about cartels because logically they should not happen. Yet as we have seen
cartels do happen. The evidence is compelling that collusive agreements are not uncommon
and firms do pursue cooperative strategies. The prisoners’ dilemma argument cannot be the
full story. There must be some way that firms can create incentives that will sustain cartel
agreements among them.


Zenda. In an effort to obtain a confession, Sergeant First Brigadier Morse has had the
two suspects brought in and subjected to separate questioning. Each is given the following
options: (1) Confess (and implicate the other), or (2) Do Not Confess. Morse indicates to
each suspect that if only one suspect confesses, she will be released in return for providing
evidence against the other and spend no time in jail. The one not confessing in this case
will “have the book thrown at her” and do ten years. If both confess, Morse indicates that
he will be a bit more lenient and each will spend six years behind bars. When asked what
will happen if neither confesses, Morse responds that he will find some small charge that
he knows will stick, so that, in this case, each will do at least one year.
Using Confess and Do Not Confess as the possible actions of either Jacoby or Myers, derive
the payoff matrix and Nash equilibrium for the game between these prisoners of Zenda.


In the last thirty years, economists have come to understand that there is a clear way
around the logic of the prisoners’ dilemma. The trick is for firms to look at their strategic
interaction from a more dynamic perspective than that of the static Cournot and Bertrand
models. Specifically, the firms need to recognize that their interaction is likely to be repeated
over time. This allows firms to base their choice in any one period on how it will affect
outcomes not only in the present but in future periods as well. With this modification it
becomes possible for the firms that are party to a collusive agreement to reward “good”
behavior by sticking with the agreement and to punish “bad” behavior by guaranteeing
a breakdown in the cartel. However, in order to understand such a strategy we need to
analyze what is called a repeated game—games in which a simultaneous market interaction
is repeated, perhaps for many times. By moving from one period to many, we are changing
the rules of the game.


14.2 REPEATED GAMES


Refer to the game of Table 14.3(a). Collusion between the two firms to produces the
monopoly output is unsustainable in that it is not a Nash equilibrium to the single period
game. Now suppose that firm 2 thinks forward a bit, knowing that its interactions with firm
1 are going to occur several, perhaps many, times. Suppose further that firm 1 has indicated


Price Fixing, Repeated Games, and Antitrust Policy 355


that it will play cooperatively so long as firm 2 does, but that once firm 2 defects, firm 1
will never cooperate again. In that case, firm 2 might calculate as follows: “If I cheat on the
cartel my profits go up to $2,025 and I gain a one-off increase in profits of $225. But then
the cartel falls apart, and we revert to the noncooperative, Cournot equilibrium with profits
to me of $1,600 per period, so that I earn $200 less per period than if I had not cheated in
the first place. Is it worth my while to cheat?”

Quite possibly, the answer is no. Depending on how firm 2 discounts future profits and
how credible firm 1’s punishment actually is, the short, one-period gain of $225 from
defecting may be offset by the loss of $200 every period thereafter. Whether or not this is
in fact the case—whether or not firm 2’s cooperation is fully reasonable—remains to be
seen. Nevertheless, one can see that moving from a static one-period game to a repeated
game may alter a firm’s thinking in a manner that dramatically raises the profitability
of cooperative, cartel behavior. When the market interaction among firms extends over a
number of periods, there is the real possibility that cartel members are able to retaliate
against defectors. Because potential defectors will rationally anticipate such retaliation, this
punishment threat is a deterrent—stopping the noncooperative behavior before it starts.

The formal description of a strategy for a repeated game is quite complicated because
current and future actions are now conditional on past actions. That is, a firm’s action
today depends critically on what has happened in previous plays of the game. To get
some idea of how rapidly the complexity grows, consider the simple Cournot game in
Table 14.3(a). Suppose that this game, which we will call the stage game, is played three
times in succession. At the end of the first round there are four possible outcomes, that
is, four possible histories. At the end of the second round, we have sixteen possible game
histories—four second-round outcomes for each of the first-round results. By the third
round, sixty-four game histories are possible—and this assumes that there are only two
players with two possible actions to take in each round. Because, formally speaking, a
strategy must define how a player acts at each round of play depending on the precise
history of the game to that point, the complexity introduced by considering repeated games
is formidable.

There are, fortunately, a few mental shortcuts available to us. The critical concept in this
regard is the familiar one of Nash equilibrium. It is possible to identify the Nash equilibrium
or equilibria for a repeated game relatively quickly if one keeps a few key principles clearly
in mind. We can best illustrate these by working through our Cournot example.

Recall that when this game is played once its only equilibrium is that both firms defect.
This is referred to as the “one-shot” equilibrium. Our interest is to see what happens when
the firms interact with each other over and over again. We shall show that the key factor is
whether the interaction is repeated over a finite (though perhaps large) number of periods
or whether it goes on forever indefinitely. In other words, we can separate repeated games
into two classes: (1) those in which the number of repetitions is finite _and known to the_
_potentially colluding firms_, and (2) those in which the number of repetitions is infinite.


14.2.1 Finitely Repeated Games


When is it reasonable to assume that the number of times that the firms interact is finite _and_
_known to both firms_ ? At least three situations come to mind. First, it may be that the firms
exploit an exhaustible and nonrenewable resource such as oil or natural gas with a given
total supply that will definitely be exhausted beyond a certain date. Secondly, the firms
might operate in a market with proprietary knowledge protected by patents. Because all


356 Anticompetitive Behavior and Antitrust Policy


patents are awarded for a finite period, say, twenty years, the date of patent expiration can
mark the date at which many new entrants emerge and cooperation ceases. For example, the
antipsychotic drugs, _Zyprexa_ and _Seroquel_, have recently dominated the market for treatment
of schizoprenia, bipolar disorder, and other severe mental illnesses. Protected by their patents
from any new rivals, the makers (Eli Lilly and AstraZeneca) of these two drugs could act
as duopolists and perhaps work out a tacit collusive agreement. That becomes much less
likely once the patents expire and new entrants can compete away the profits of those firms.

Finally, while we conventionally equate the players in the game with firms, the truth
is that it is ultimately individuals who make the output or price decisions. The same
management teams can be expected to be around for only a finite number of years. When
there is a major change in management at one or more of the firms the initial game will
likely end and this end can often be foreseen.

It turns out that what happens in a one-shot or stage game gives us a very good clue
to what is likely to happen in a repeated game when the number of repetitions is finite.
After all, a one-period game is just one that is very finite. Consider a simple extension of
our Cournot game from one-period to two and determine what the equilibrium will be in
this limited but nonetheless repeated setting. [6] When we do this we find that the two-period
repeated game will have the same noncooperative outcome in each round as the one-shot
game. To see why, consider the following alternative strategy for firm 1:


_First play_ : Cooperate

_Second play_ : Cooperate if firm 2 cooperated in the first play, otherwise Defect.


The idea behind this strategy is clear enough. Start off on a friendly footing. If this results
in cooperation in the first round, then in the second round, firm 1 promises to continue to
cooperate. However, should firm 2 fail to reciprocate firm 1’s initial cooperation in the first
round, that “triggers” firm 1 to then take “take the gloves off” and fight back in the second
round. For this reason, this sort of strategy is called a “trigger” strategy.

The problem with this strategy is that it suffers from the same basic credibility problem
that afflicted many of the predatory threats that we discussed in the preceding chapters.
To see why, suppose firm 2 chooses to cooperate in the first round. Now think of firm 2’s
position at the start of its second and last interaction with firm 1. The history of play to that
point is one in which both firms adopted cooperative behavior in the first round. Further,
firm 2 has a promise from firm 1 that, because firm 2 cooperated in the first round, firm 1 will
continue to do so in the second. However, this promise is worthless. When firm 2 considers
the payoff matrix for the last round, the firm cannot fail to note that—regardless of firm 1’s
promise—the dominant strategy for firm 1 in the last round is not to cooperate. This breaks
firm 1’s promise, but there is nothing firm 2 can subsequently do to punish firm 1 for breaking
its promise. There is no third round in which to implement such punishment. Firm 2 should
rationally anticipate that firm 1will adopt the noncooperative behavior in the last round.

Firm 2 has just discovered that any strategy for firm 1 that involves playing the cooperative
strategy in the final round is not credible, i.e., it is not subgame perfect. The last round
of the game is a subgame of the complete game, and a strategy that calls for firm 1 to
cooperate in this last period cannot be part of a Nash equilibrium in that period. No matter
what has transpired in the first round, firm 1 can be counted upon to adopt noncooperative


6 Even though the game lasts for two market periods, we will keep things simple and assume that profits in
the second period are not discounted. In other words, we will assume that the discount factor _R_ = 1 or,
equivalently, the interest rate r = 0%. See the discussion of discounting in Chapter 2.


Price Fixing, Repeated Games, and Antitrust Policy 357


behavior in the final period of play. Of course, the same is true when viewed from firm 1’s
perspective. Firm 2’s best strategy in the last round is likewise not to cooperate. In short,
both firms realize that the only rational outcome in the second round is the noncooperative
equilibrium in which each earns a profit of $1,600.

The fact that we have identified the equilibrium in the final round may seem like only a
small part of the solution that we were originally seeking—especially if the game has 10
or 100 rounds instead of just 2. However, as you may recall from the Chain-Store Paradox
in Chapter 11, the outcome for the terminal round can lead directly to a solution of the
entire game. Consider again our two-period repeated game. In the first round, firm 1 will
now see that firm 2’s best first-round strategy is not to cooperate. The only reward that
firm 1 can offer to persuade firm 2 from such noncooperative action in the first round is
the promise of cooperation in the future in return for firm 2 cooperating today. Yet such a
promise is not credible. No matter how passionately firm 1 promises to cooperate tomorrow
in return for cooperation today, firm 2 will recognize that when tomorrow actually comes,
firm 1 will not cooperate. It follows that the only hope firm 1 had of dissuading firm 2 from
noncooperative action in the first round is gone.

Again symmetry implies the same reasoning holds true for any hope firm 2 had of inducing
cooperation from firm 1. Hence, we have identified the subgame perfect equilibrium for the
entire game. Both firms adopt strategies that call for noncooperative behavior in _both_ period
one and period two. In other words, running the game for two periods produces outcomes
identical to those observed by playing it as a one-period game.


three periods. What will be the outcome in the final period? What does this imply about the
incentive to cooperate in period two? If both firms believe that there will be no cooperation
in either period two or period three, will either cooperate in period one?


We have identified the subgame perfect equilibrium for our example when the game is
played for two periods. However, as Practice Problem 14.2 illustrates, our reasoning also
extends to a solution for the game whether it is played two, three, or any finite number of
periods, _T_ . In all such cases, no strategy that calls for cooperation in the final period is
subgame perfect. Therefore, no such strategy can be part of the final equilibrium. In the
last period, each firm always chooses not to cooperate regardless of the history of the game
to that point. But this means that the same noncooperative behavior must also characterize
the penultimate, or _T_ - 1, period. The only possible gain that might induce either firm 1 or
firm 2 to cooperate in period _T_ - 1 is the promise of continued cooperation from its rival
in the future. Because such a promise is not credible, both firms adopt noncooperativebehavior in both period _T_ - 1 and period _T_ . In other words, any strategy that calls for
cooperative behavior in either of the last two periods can also be ruled out as part of the
final equilibrium. An immediate implication is that a three-period game must be one in
which the players simply repeat the one-shot Nash equilibrium three times.

We can reiterate this logic for larger and larger values of _T_ . The outcome will always be
the same Nash equilibrium as in our first example no matter how many times it is played,
so long as that number is finite and known. The one-shot Nash equilibrium is just repeated
_T_ times, with each firm taking noncooperative action in every period.




358 Anticompetitive Behavior and Antitrust Policy


The foregoing result is by no means a special case. Rather, that analysis is an example of
a general theorem first proved by Nobel Prize winner Reinhard Selten (1973):


_Selten’s Theorem_ : If a game with a unique equilibrium is played finitely many times, its
solution is that equilibrium played each and every time. Finitely repeated play of a unique
Nash equilibrium is the Nash equilibrium of the repeated game. [7]


Introducing repetition into a game theoretic framework adds history as an element to the
analysis. When players face each other over and over again, they can adopt strategies that
base today’s action on the behavior of their rivals in previous periods. This is what rewards
and punishments are all about. What Selten’s Theorem demonstrates is that history, or
rewards and punishments, really do not play a role in a finitely repeated game in which the
basic one-shot game has a unique Nash equilibrium.


14.2.2 Infinitely or Indefinitely Repeated Games


As noted above, there are situations in which the assumption of finite repetition makes a
great deal of sense and therefore to which Selten’s Theorem applies. However for many,
and perhaps most, situations, firms are better regarded as having an infinite or, more
precisely, an indefinite life. Google may not last forever, but nobody inside or outside this
giant telecommunications firm knows of a date _T_ periods from now at which point Google
will cease to exist. Our assumption that everyone knows the final period with certainty is
therefore likely to be too strong. The more likely situation is that after any given period,
the players see some positive probability that the game will continue one more round. So,
while firms may understand that the game will not last forever, they cannot look ahead to
any particular period as the last.

Why is this important? Recall the argument that we used to show that finite repetition will
not lead to cooperation in a Cournot or Bertrand game. Cooperation is not an equilibrium
in the final period _T_, and so is not an equilibrium in _T_ - 1, and so in _T_ - 2, and so on.
With infinite or indefinite repetition of the game this argument fails _because there is no_
_known final period_ . So long as the probability of continuing into another round of play
is positive, there is, probabilistically speaking, reason to hope that the next round will be
played cooperatively and so reason to cooperate in the present. Whether that motivation
is strong enough to overcome the short-run gains of defection, or can be made so by
means of some reward-and-punishment strategy will depend on certain key factors that we
discuss below. We will see that once we permit the possibility that strategic interaction will
continue indefinitely, the possibility of successful collusion becomes a good bit more real.

In developing the formal analysis of an indefinitely repeated game, we must first consider
how a firm values a profit stream of infinite duration. The answer is simply that it will apply
the discount factor _R_ to the expected cash flow in any period. Suppose that a firm knows
that its profits are going to be _π_ in each play of the game. Suppose also that the firm knows
that in each period there is a probability _p_ that the market interaction will continue into the
next period. Then starting from an initial period 0, the probability of reaching period 1 is _p_,
the probability of reaching period 2 is _p_ [2], of reaching period 3 is _p_ [3] _, . . ._ of reaching period
_t_ is _p_ _[t]_ and so on. Accordingly, the profit stream that the firm actually expects to receive in
period t is _p_ _[t]_ _π_ .


7 A formal proof can be found, for example, in Eichberger (1993).


Price Fixing, Repeated Games, and Antitrust Policy 359


Now apply the firm’s discount factor is _R_ . The expected present value of this profit
stream is given by:


_V (π)_ = _π_ + _pRπ_ + _(pR)_ [2] _π_ + _(pR)_ [3] _π_ + _. . ._ + _(pR)_ _[t]_ _π_ + _. . ._ (14.1)


To evaluate _V (π)_ we use a simple trick. Rewrite equation (14.1) as:



_π_ + _pRπ_ + _(pR)_ [2] _π_ + _(pR)_ [3] _π . . ._ + _(pR)_ _[t]_ _π_ + _. . ._



(14.2)







_V (π)_ = _π_ + _pR_







Now note that the term in brackets is just _V (π)_ as given by (14.1), so (14.2) can be
rewritten:


_V (π)_ = _π_ + _pRV(π)_


Solving this for _V (π)_ then gives:


_π_ _π_
_V (π)_ (14.3)
= 1 _pR_ 1 _ρ_
     - [=]      
where _ρ_ = _pR_ can be thought of as a “probability-adjusted” discount factor. It is the product
of the discount factor reflecting the interest rate and the belief the firm holds regarding the
probability that the market will continue to operate from period to period.

As suggested above, repetition allows history to play a role in strategy making. In fact,
many variants of the trigger strategy that would not work in the finitely repeated game will
work in the infinitely repeated one. We focus on perhaps the simplest of these in which
each player promises to play the cooperative action upon which all players have agreed as
long as the history of the game to that point does not reveal any defections. However, if
any player should deviate from the agreement then our trigger-strategy player promises to
revert to the one-shot Nash equilibrium forever.

Consider again our simple duopoly example for both the Bertrand and Cournot case. [8]

Suppose that the firms formulate a price-fixing agreement that gives them both profits of
_π_ _[M]_ (one half each of the combined monopoly profit). Each firm knows that if it deviates
optimally from this agreement it will earn in that period of deviation a profit of _π_ _[D]_ . Finally,
denote the noncooperative Nash equilibrium profit to each firm as _π_ _[N]_ . Common sense and
our Cournot and Bertrand examples of Table 14.3 tell us that _π_ _[D]_ _> π_ _[M]_ _> π_ _[N]_ .

Now consider the following trigger strategy:


_Period 0_ : Cooperate.

_Period t > 1_ : Cooperate if both firms have cooperated in every previous period. Switch to the
Nash equilibrium forever if either player has defected in any previous period.


A firm whose rival is following this strategy then faces the following choice. Continue
to cooperate and earn _π_ _[M]_ or defect from cooperative play and earn _π_ _[D]_ for one period but
only _π_ _[N]_ in every subsequent period because that defection will trigger the rival to move to
the noncooperative equilibrium permanently in that following period.


8 Our analysis generalizes to an _n_ -firm oligopoly as we note below.


360 Anticompetitive Behavior and Antitrust Policy


The only way to compare the gain with the loss is in terms of present values. The present
value of profits from sticking to the agreement is, using equation (14.3):



_π_ _[M]_
_V_ _[C]_ _π_ _[M]_ _ρπ_ _[M]_ _ρ_ [2] _π_ _[M]_ _. . ._
= + + + = 1



(14.4)
1 − _ρ_



In contrast, the present value of firm 2’s profits if it deviates is:



_V_ _[D]_ = _π_ _[D]_ + _ρπ_ _[N]_ + _ρ_ [2] _π_ _[N]_ + _ρ_ [3] _π_ _[N]_ + _. . ._



_π_ _[D]_ _ρ_ [ _π_ _[N]_ _ρπ_ _[N]_ _ρ_ [2] _π_ _[N]_ _. . ._ ] _π_ _[D]_ _[ρπ]_ _[N]_
= + + + + = + 1



(14.5)
1 − _ρ_



Cheating on the cartel is not profitable, and so the cartel is _self-sustaining_ provided that
_V_ _[C]_ _> V_ _[D]_, which requires that:



_π_ _[M]_ _[ρπ]_ _[N]_

1 − _ρ_ _[> π]_ _[D]_ [ +] 1 −



_π_ _[M]_



(14.6)
1 − _ρ_



Multiplying both sides by _(_ 1 − _ρ)_ and simplifying gives:



_V_ _[C]_ _> V_ _[D]_ ⇒ _π_ _[M]_ _> (_ 1 − _ρ)π_ _[D]_ + _ρπ_ _[N]_ ⇒ _ρ(π_ _[D]_ - _π_ _[N]_ _) > π_ _[D]_ - _π_ _[M]_



In other words, the critical value of _ρ_ above which defection on the cartel does not pay
leading firms to voluntarily stick by the cartel agreement is:



_ρ > ρ_ [∗] _[π]_ _[D]_ [ −] _[π]_ _[M]_
= _π_ _[D]_ _π_ _[N]_



(14.7)
_π_ _[D]_ - _π_ _[N]_



Equation (14.7) has a simple underlying intuition. Cheating on the cartel yields an
immediate, one period gain of _π_ _[D]_ - _π_ _[M]_ . However, starting the next period and continuing
through every period thereafter, the punishment for cheating is a loss of profit of _π_ _[M]_ - _π_ _[N]_ .
The present value of that loss starting next period is _(π_ _[M]_ - _π_ _[N]_ _)/(_ 1 − _ρ)_ . Its present value
as of today when the profit from cheating is realized is _ρ (π_ _[M]_ - _π_ _[N]_ _)/(_ 1 − _ρ)_ . Cheating will
be deterred if the gain is less than the cost when both are measured in present value terms,
i.e., if _π_ _[D]_ - _π_ _[M]_ _< ρ (π_ _[M]_ - _π_ _[N]_ _)/(_ 1 − _ρ)_ . It is easy to show that this condition is identical
to that in equation (14.7). Because _π_ _[D]_ _> π_ _[M]_ _> π_ _[N]_ it follows that _ρ_ [∗] _<_ 1. Hence, _there is_
_always a probability-adjusted discount factor above which a cartel is self-sustaining_ .

Consider our two examples in Table 14.3. In the Bertrand case _π_ _[D]_ = 3,600 _, π_ _[M]_ =
1,800, and _π_ _[N]_ = 0. The critical probability adjusted discount factor above which our
Bertrand duopolists can sustain their cartel is _ρ_ [∗] [ 0.5. In the Cournot case we have]



Bertrand duopolists can sustain their cartel is _ρB_ [∗]

_π_ _[D]_ = 2,025 _, π_ _[M]_ = 1,800, and _π_ _[N]_ = 1,600. Substituting into (14.7) the critical probability [=][ 0.5. In the Cournot case we have]
adjusted discount factor above which our Cournot duopolists can sustain their cartel is
_ρ_ [∗] [ 0.529. Practice Problem 14.3 below asks you to prove that these critical discount]



_ρC_ [∗]

factors hold for [=][ 0.529. Practice Problem 14.3 below asks you to prove that these critical discount] _any_ Cournot or Bertrand duopoly with linear demand and constant, equal
marginal costs.

Suppose that both firms playing the Cournot game believe that their interaction will
always be repeated with certainty, so that _p_ = 1. Then the critical probability adjusted
discount factor _ρC_ [∗] [corresponds to a pure discount factor of] _[ R]_ [ =][ 0.529. That is, if] _[ p]_ [ =][ 1,]

neither firm will deviate so long as the firm’s interestrate _r_ does not exceed 89 percent. Now
suppose instead that both firms perceive only a 60 percent probability that their interaction
lasts from one period to the next, i.e., _p_ = 0.6. Now the cartel agreement is self-sustaining



Suppose that both firms playing the Cournot game believe that their interaction will
always be repeated with certainty, so that _p_ = 1. Then the critical probability adjusted
discount factor _ρ_ [∗] [corresponds to a pure discount factor of] _[ R]_ [ 0.529. That is, if] _[ p]_ [ 1,]


Price Fixing, Repeated Games, and Antitrust Policy 361


only when the pure discount factor _R >_ 0.529 _/_ 0.6 = 0.882. That is, successful collusion
now requires that the interest rate _r_ does not exceed 143.4 percent, which is a less restrictive
requirement. This example points to a general result. An indefinitely lived cartel is more
sustainable the greater is the probability that the firms will continue to interact and the
lower is the interest rate.


have the same marginal cost _c_ . Show that:


a. If the firms compete in quantities, the probability adjusted discount factor must satisfy
_ρ_ [∗] [0.529 for collusion to be sustained; and]





_ρC_ [∗]

b. If the firms compete in prices, the probability adjusted discount factor must satisfy [≥] [0.529 for collusion to be sustained; and]
_ρ_ [∗] [ 0.5 for collusion to be sustained.]



_B_ [∗]

[≥=][ 0.5 for collusion to be sustained.]



14.3 THE FOLK THEOREM AND FACTORS THAT
FACILITATE COLLUSION


Our analysis easily extends to cases where the number of firms is more than two. All we
need do is to identify the three firm-level profits _π_ _[D]_ _> π_ _[M]_ _> π_ _[N]_ for each firm. Substituting
these values into equation (14.7) then yields the critical probability-adjusted discount factor
for each firm.


14.3.1 The Folk Theorem


Yet despite its general application, the success of the trigger strategy discussed above is
far from guaranteed. To begin with, any trigger strategy is rooted in the assumption that
cheating on the cartel agreement is detected quickly and that punishment is swift. If instead,
detection and punishment of cheaters takes time then sustaining the cartel becomes more
difficult because it allows the defecting firm to enjoy the gains for more periods and this
raises the incentive to defect.

A further and related issue is that the trigger strategy employed above is potentially too
harsh and unforgiving for a world of uncertainty and miscommunication. For example,
suppose that market demand fluctuates within some known bounds, as shown in Figure 14.1,
and that the cartel has agreed to set a price _P_ _[C]_ or has agreed to production quotas that lead
to that market price. In this setting, a cartel firm that observes a decline in its sales cannot
tell whether this reduction is due to cheating by one of its partners or to an unanticipated
reduction in demand. Yet under the simple trigger strategies we have been discussing, the
firm is required quickly and permanently to move to the retaliatory behavior. Clearly, this
will lead to some regret if the firm later discovers that its partners were innocent and that it
has needlessly unleashed a damaging price war. [9]

In general, these obstacles to the use of a trigger strategy are important but they can in
principle be overcome. Even if detection and punishment is not swift, it can still be effective


9 Two different views of oligopolistic behavior with uncertain demand that makes detection difficult may be
found in Green and Porter (1984) and Rotemberg and Saloner (1986).


362 Anticompetitive Behavior and Antitrust Policy


_PC_

|D<br>H<br>D<br>D M<br>L|Col2|Col3|
|---|---|---|
|||_DL_|



_QL_ _QM_ _QH_

Quantity





**Figure 14.1** Cartel maintenance with uncertain demand
If demand is uncertain and varies between _DL_ and _DH_ with a mean of _DM_, cartel members will not be able to
tell whether a variation in their output is the result of normal variation in the market or cheating by other cartel
members.


if the probabilistic discount factor is sufficiently large, i.e., if firms place a sufficiently
large weight on the future monopoly profits that cooperation makes possible. Likewise, the
issue of uncertainty can be met by adopting a modified trigger strategy. For instance, the
firm might only take retaliatory action if sales or price fall outside some agreed range, i.e.,
the firm refrains from retaliation against minor infractions. A different modification would
impose punishment swiftly after any deviation, including a minor one, is observed but limit
the period of punishment to a finite period of time. Thus, we can envision a trigger strategy
of the form “I will switch to the Nash equilibrium for _τ_ ≥ 1 periods if you deviate from our
agreement but will then revert to our agreed cooperative strategies.” This approach may
mistakenly punish innocent cartel members but, by limiting the period of such punishment,
it permits reestablishment of the cartel at a later date.

The point is that in an infinitely repeated game there are many trigger strategies that allow
a cartel agreement to be sustained. Indeed, in some ways, there are almost too many. This
point is made clear by what is known as the _Folk Theorem_ for infinitely repeated games
(Friedman 1971): [10]


_Folk Theorem_ : Suppose that an infinitely repeated game has a set of payoffs that exceed the
one-shot Nash equilibrium payoffs for each and every firm. Then any set of feasible payoffs
that are preferred by all firms to the Nash equilibrium payoffs can be supported as subgame
perfect equilibria for the repeated game for some discount rate sufficiently close to unity.


We can illustrate the Folk Theorem using our Cournot example. If the two firms
collude to maximize their joint profits, they share aggregate profits of $3,600. If they act
noncooperatively they each earn $1,600. The Folk Theorem says that any cartel agreement
in which each firm earns more than $1,600 and in which total profit does not exceed $3,600
can, at least in principle, be sustained as a subgame perfect equilibrium of the infinitely
repeated game. The shaded region of Figure 14.2 shows the range of profits for this example
that can be earned by each firm in a sustainable cartel.


10 The term “Folk Theorem” derives from the fact that this theorem was part of the “folklore” or oral
tradition in game theory for years before Friedman wrote down a formal proof.


Price Fixing, Repeated Games, and Antitrust Policy 363



![](/Users/nicholasvreugdenhil/ASU Dropbox/Nicholas Vreugdenhil/masters_io_2026/external/peppall_textbook_chunks/markdown/peppall_textbook_chunk15_p351-375_images/peppall_textbook_chunk15_p351-375.pdf-24-0.png)

2.1


2.0


1.6


1.5 1.6



Π1



2.1



2.0



**Figure 14.2** The Folk Theorem
Any distribution of profits in the shaded area can be supported by a trigger strategy for some discount factor
sufficiently close to unity.


A qualifying note should be added here. The Folk Theorem does not say that firms can
always achieve a total industry profit equal to that earned by a monopoly. It simply says that
firms can do better than the noncooperative, Cournot–Nash or Bertrand-Nash equilibrium.
The reason that exact duplication of monopoly may not be possible is that the monopoly
outcome always results in the highest possible price relative to marginal cost. At such a high
price, any cartel member can earn substantial short-term profit with even a small deviation
from the cartel agreement. Consequently, duplicating the monopoly outcome gives members
a tremendous incentive to cheat unless the probability adjusted discount factor is fairly
large. Yet the incentive to deviate and break the monopoly agreement does not mean that
no cartel can be sustained. Firms can still earn profits higher than the noncooperative
equilibrium by means of a sustainable cartel agreement, even if they cannot earn the highest
possible profits that the industry could yield. This is what the Folk Theorem says.


14.3.2 Factors Facilitating Collusion


In sum, the Folk Theorem tells us that some collusion is always a possiblility subject to
two qualifications. First, the probabilistic discount factor must be sufficiently close to unity.
Second, while collusion may be possible, the profit resulting from it may not be very large
relative to the noncooperative outcome. It is natural then to ask under what conditions
these qualifications will be important. That is, what factors make successful and profitable
collusion likely?

While a complete list of all the factors that make successful collusion more likely would
be very long, we concentrate here on seven factors that are particularly important. These are
1) high concentration/small number of firms; 2) barriers to entry; 3) frequent and regular
orders; 4) rapid market growth; 5) technology and cost similarities; 6) product homgeneity;
and 7) multimarket contact. We discuss each of these in turn.


_Concentated Markets/Small Number of Firms_


We are more likely to find collusion in more concentrated markets for at least two reasons.
First, increased concentration typically reduces the critical probability-adjusted discount


